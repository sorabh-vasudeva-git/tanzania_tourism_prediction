{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import missingno\n",
    "\n",
    "\n",
    "# data preprocessing \n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "# model selection & validation\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split,\n",
    "    cross_val_score,\n",
    "    StratifiedKFold,\n",
    "    GridSearchCV,\n",
    "    RandomizedSearchCV\n",
    ")\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, f1_score, log_loss, confusion_matrix, classification_report\n",
    "from sklearn.dummy import DummyClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "# model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestClassifier,\n",
    "    BaggingClassifier,\n",
    "    VotingClassifier,\n",
    "    StackingClassifier,\n",
    "    AdaBoostClassifier,\n",
    "    GradientBoostingClassifier,\n",
    "    ExtraTreesClassifier,\n",
    "    RandomForestRegressor,\n",
    "    GradientBoostingRegressor\n",
    ")\n",
    "\n",
    "# XGBoost\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# evaluation \n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    confusion_matrix,\n",
    "    classification_report,\n",
    "    roc_auc_score,\n",
    "    roc_curve\n",
    ")\n",
    "\n",
    "\n",
    "RSEED = 42\n",
    "\n",
    "\n",
    "import string\n",
    "import warnings\n",
    "import missingno\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "df_train = pd.read_csv('data/train.csv')\n",
    "df_test = pd.read_csv('data/test.csv')\n",
    "df_all = pd.concat((df_train, df_test)).reset_index(drop=True)\n",
    "\n",
    "\n",
    "# 경고창 해체 \n",
    "from sklearn.metrics import accuracy_score\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Y = total_cost\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print(df_train.shape)\n",
    "# print(df_train.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# missingno.matrix(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cat_cols = df_train.select_dtypes(include='category').columns\n",
    "for col in cat_cols:\n",
    "    df_train[col] = df_train[col].str.strip().str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train['travel_with'] = df_train['travel_with'].str.lower().str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# sns.histplot(df_train['total_cost'], kde=True)\n",
    "# plt.title(\"Original Total Cost Distribution\")\n",
    "# plt.show()\n",
    "\n",
    "# df_train['log_total_cost'] = np.log1p(df_train['total_cost'])\n",
    "\n",
    "# sns.histplot(df_train['log_total_cost'], kde=True)\n",
    "# plt.title(\"Log-Transformed Total Cost\")\n",
    "# plt.show()\n",
    "\n",
    "# sns.boxplot(x=df_train['total_cost'])\n",
    "# plt.title(\"Original _ Boxplot of Total Cost\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# after log\n",
    "# sns.boxplot(x=df_train['log_total_cost'])\n",
    "# plt.title(\"Boxplot of Log-Transformed Total Cost\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# df_train.head(5)  \n",
    "# new feature ---> log_total_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train['total_female'] = df_train['total_female'].fillna(0) #total_female 또는 total_male에 값이 비어 있으면(NaN) → 0으로 바꾼다\n",
    "df_train['total_male'] = df_train['total_male'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train['travel_with'] = df_train['travel_with'].fillna('alone')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ✅ 1. 파생변수 생성\n",
    "# -------------------------\n",
    "# group_size\n",
    "df_train['group_size'] = df_train['total_female'] + df_train['total_male']\n",
    "\n",
    "# total_nights\n",
    "df_train['total_nights'] = df_train['night_mainland'] + df_train['night_zanzibar']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# BOX PLOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "\n",
    "\n",
    "# cat_cols = df_all.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "\n",
    "# target = 'total_cost'\n",
    "\n",
    "# for col in cat_cols:\n",
    "#     if col == target: \n",
    "#         continue\n",
    "    \n",
    "#     plt.figure(figsize=(10, 6))\n",
    "#     sns.boxplot(data=df_all, x=col, y=target)\n",
    "#     plt.xticks(rotation=45)\n",
    "#     plt.title(f'Total Cost by {col}')\n",
    "#     plt.xlabel(col)\n",
    "#     plt.ylabel('Total Cost')\n",
    "#     plt.tight_layout()\n",
    "#     plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_cols = df_train.select_dtypes(include='number').columns.tolist()\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "\n",
    "# # 전체 수치형 컬럼 히스토그램 반복 출력\n",
    "# for col in num_cols:\n",
    "#     plt.figure(figsize=(6, 4))\n",
    "#     sns.histplot(df_train[col].dropna(), kde=True)\n",
    "#     plt.title(f\"Distribution of '{col}'\")\n",
    "#     plt.xlabel(col)\n",
    "#     plt.ylabel(\"Count\")\n",
    "#     plt.tight_layout()\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# groupby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import seaborn as sns\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# for col in cat_cols:\n",
    "#     if col == 'ID':\n",
    "#         continue\n",
    "#     plt.figure(figsize=(10, 5))\n",
    "#     sns.boxplot(data=df_train, x=col, y='total_cost')\n",
    "#     plt.xticks(rotation=45)\n",
    "#     plt.title(f'Total Cost by {col}')\n",
    "#     plt.tight_layout()\n",
    "#     plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# cat_cols = df_train.select_dtypes(include='object').columns.tolist()\n",
    "\n",
    "# cat_cols = [col for col in cat_cols if col != 'ID']\n",
    "\n",
    "# median_cost_by_category = {}\n",
    "\n",
    "# for col in cat_cols:\n",
    "#     median_values = df_train.groupby(col)['total_cost'].median().sort_values(ascending=False)\n",
    "#     median_cost_by_category[col] = median_values\n",
    "\n",
    "# for col, medians in median_cost_by_category.items():\n",
    "#     print(f\"\\n▶ {col} by total_cost_Ranking by median:\")\n",
    "#     print(medians)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print(df_train['total_cost'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train.drop(columns=[\n",
    "    'most_impressing',\n",
    "    'info_source',\n",
    "    'first_trip_tz',\n",
    "], inplace=True, errors='ignore')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Evaluation metrics "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Splite X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train = df_train.drop(['total_cost'], axis=1)\n",
    "y_train = df_train['total_cost']\n",
    "\n",
    "X_test = df_test.drop('total_cost', axis=1, errors='ignore')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# DummyRegression = Baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAPE (cross-val): 1112.44%\n",
      "MAE (cross-val): 8,060,531 TZS\n"
     ]
    }
   ],
   "source": [
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error, make_scorer\n",
    "\n",
    "\n",
    "X = df_train.drop(['total_cost'], axis=1)\n",
    "y = df_train['total_cost']\n",
    "\n",
    "dummy_cv = DummyRegressor(strategy='mean')\n",
    "\n",
    "y_pred = cross_val_predict(dummy_cv, X, y, cv=5)\n",
    "\n",
    "\n",
    "mape = mean_absolute_percentage_error(y, y_pred)\n",
    "print(f\"MAPE (cross-val): {mape:.2%}\")\n",
    "\n",
    "\n",
    "mae_scorer = make_scorer(mean_absolute_error, greater_is_better=False)\n",
    "mae_scores = cross_val_score(dummy_cv, X, y, scoring=mae_scorer, cv=5)\n",
    "print(f\"MAE (cross-val): {-mae_scores.mean():,.0f} TZS\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# RandomForest + GridSearchCV + 예측 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params: {'regressor__max_depth': 10, 'regressor__min_samples_leaf': 3, 'regressor__n_estimators': 100}\n",
      "Best MAE (CV): 5059731.829232073\n",
      "\n",
      " final metrics (Train Set focused)\n",
      "MAE  : 4,047,545 TZS\n",
      "RMSE : 7,427,021 TZS\n",
      "MAPE : 293.26%\n",
      "R²   : 0.6308\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_absolute_percentage_error, r2_score\n",
    "\n",
    "\n",
    "X_train = df_train.drop(['total_cost'], axis=1)\n",
    "y_train = df_train['total_cost']\n",
    "X_test = df_test.copy()  # test에는 정답 없음\n",
    "\n",
    "\n",
    "numeric_features = X_train.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "cat_features = X_train.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "cat_pipeline = Pipeline([\n",
    "    ('imputer_cat', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('1hot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', num_pipeline, numeric_features),\n",
    "    ('cat', cat_pipeline, cat_features)\n",
    "])\n",
    "\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', RandomForestRegressor(\n",
    "        n_estimators=300,\n",
    "        max_depth=20,\n",
    "        min_samples_leaf=3,\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "\n",
    "param_grid = {\n",
    "    'regressor__n_estimators': [100],\n",
    "    'regressor__max_depth': [10, 20],\n",
    "    'regressor__min_samples_leaf': [3]\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    pipeline,\n",
    "    param_grid,\n",
    "    cv=5,\n",
    "    scoring='neg_mean_absolute_error',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best Params:\", grid.best_params_)\n",
    "print(\"Best MAE (CV):\", -grid.best_score_)\n",
    "\n",
    "\n",
    "best_model = grid.best_estimator_\n",
    "y_pred = best_model.predict(X_train)  \n",
    "\n",
    "mae = mean_absolute_error(y_train, y_pred)\n",
    "mse = mean_squared_error(y_train, y_pred) \n",
    "rmse = np.sqrt(mse)  \n",
    "mape = mean_absolute_percentage_error(y_train, y_pred)\n",
    "r2 = r2_score(y_train, y_pred)\n",
    "\n",
    "print(\"\\n final metrics (Train Set focused)\")\n",
    "print(f\"MAE  : {mae:,.0f} TZS\")\n",
    "print(f\"RMSE : {rmse:,.0f} TZS\")\n",
    "print(f\"MAPE : {mape:.2%}\")\n",
    "print(f\"R²   : {r2:.4f}\")\n",
    "\n",
    "# test start \n",
    "\n",
    "\n",
    "# test_preds = best_model.predict(X_test)\n",
    "\n",
    "\n",
    "# submission = pd.DataFrame({\n",
    "#     'id': X_test['ID'],  # 또는 test에 'id' 컬럼이 있다면 'df_test[\"id\"]' 사용\n",
    "#     'prediction': test_preds\n",
    "# })\n",
    "\n",
    "\n",
    "# submission.to_csv('randomforest_submission.csv', index=False)\n",
    "# print(\"test y value result: submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# XGBOOST + outlier remove"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " final metrics (Train Set focused)\n",
      "MAE  : 3,022,735 TZS\n",
      "RMSE : 4,718,013 TZS\n",
      "MAPE : 245.80%\n",
      "R²   : 0.8186\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "def remove_outliers_iqr(df, columns):\n",
    "    df_clean = df.copy()\n",
    "    for col in columns:\n",
    "        Q1 = df_clean[col].quantile(0.25)\n",
    "        Q3 = df_clean[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "        df_clean = df_clean[(df_clean[col] >= lower_bound) & (df_clean[col] <= upper_bound)]\n",
    "    return df_clean\n",
    "\n",
    "train_df = X_train.copy()\n",
    "train_df['target'] = y_train\n",
    "\n",
    "numeric_cols = train_df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "numeric_cols.remove('target')\n",
    "\n",
    "df_clean = remove_outliers_iqr(train_df, numeric_cols)\n",
    "\n",
    "X_clean = df_clean.drop('target', axis=1)\n",
    "y_clean = df_clean['target']\n",
    "\n",
    "\n",
    "numeric_features = X_clean.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "cat_features = X_clean.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "cat_pipeline = Pipeline([\n",
    "    ('imputer_cat', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('1hot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', num_pipeline, numeric_features),\n",
    "    ('cat', cat_pipeline, cat_features)\n",
    "])\n",
    "\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('xgb', XGBRegressor(\n",
    "        n_estimators=200,\n",
    "        max_depth=6,\n",
    "        learning_rate=0.1,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    ))\n",
    "])\n",
    "\n",
    "\n",
    "pipeline.fit(X_clean, y_clean)\n",
    "\n",
    "\n",
    "y_pred = pipeline.predict(X_clean)\n",
    "\n",
    "mae = mean_absolute_error(y_clean, y_pred)\n",
    "mse = mean_squared_error(y_clean, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "mape = mean_absolute_percentage_error(y_clean, y_pred)\n",
    "r2 = r2_score(y_clean, y_pred)\n",
    "\n",
    "print(\"\\n final metrics (Train Set focused)\")\n",
    "print(f\"MAE  : {mae:,.0f} TZS\")\n",
    "print(f\"RMSE : {rmse:,.0f} TZS\")\n",
    "print(f\"MAPE : {mape:.2%}\")\n",
    "print(f\"R²   : {r2:.4f}\")\n",
    "\n",
    "\n",
    "# test starts\n",
    "\n",
    "# test_preds = pipeline.predict(X_test)\n",
    "\n",
    "# submission = pd.DataFrame({\n",
    "#     'id': X_test['ID'],  # 또는 test에 'id' 컬럼이 있다면 'df_test[\"id\"]' 사용\n",
    "#     'prediction': test_preds\n",
    "# })\n",
    "\n",
    "# submission.to_csv('submission.csv', index=False)\n",
    "# print(\" test y value file : submission.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tunning (XGBRegressor + GridSearchCV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "✅ Best Params: {'xgb__colsample_bytree': 0.8, 'xgb__learning_rate': 0.05, 'xgb__max_depth': 9, 'xgb__n_estimators': 200, 'xgb__subsample': 0.8}\n",
      "✅ Best MAE (CV): 4236937.9739013165\n",
      "\n",
      " final metrics (Train Set focused)\n",
      "MAE  : 2,715,403 TZS\n",
      "RMSE : 4,260,343 TZS\n",
      "MAPE : 229.07%\n",
      "R²   : 0.8521\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "param_grid = {\n",
    "    'xgb__n_estimators': [100, 200,500],\n",
    "    'xgb__max_depth': [3, 6,9],\n",
    "    'xgb__learning_rate': [0.05, 0.1, 1],\n",
    "    'xgb__subsample': [0.8],\n",
    "    'xgb__colsample_bytree': [0.8]\n",
    "}\n",
    "\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('xgb', XGBRegressor(\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        verbosity=0\n",
    "    ))\n",
    "])\n",
    "\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    estimator=pipeline,\n",
    "    param_grid=param_grid,\n",
    "    cv=5,\n",
    "    scoring='neg_mean_absolute_error',\n",
    "    verbose=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grid.fit(X_clean, y_clean)\n",
    "\n",
    "print(\"✅ Best Params:\", grid.best_params_)\n",
    "print(\"✅ Best MAE (CV):\", -grid.best_score_)\n",
    "\n",
    "\n",
    "best_model = grid.best_estimator_\n",
    "y_pred = best_model.predict(X_clean)\n",
    "\n",
    "mae = mean_absolute_error(y_clean, y_pred)\n",
    "mse = mean_squared_error(y_clean, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "mape = mean_absolute_percentage_error(y_clean, y_pred)\n",
    "r2 = r2_score(y_clean, y_pred)\n",
    "\n",
    "print(\"\\n final metrics (Train Set focused)\")\n",
    "print(f\"MAE  : {mae:,.0f} TZS\")\n",
    "print(f\"RMSE : {rmse:,.0f} TZS\")\n",
    "print(f\"MAPE : {mape:.2%}\")\n",
    "print(f\"R²   : {r2:.4f}\")\n",
    "\n",
    "\n",
    "# test starts \n",
    "\n",
    "# test_preds = best_model.predict(X_test)\n",
    "\n",
    "# submission = pd.DataFrame({\n",
    "#     'id': X_test['ID'],  # 또는 test에 'id' 컬럼이 있다면 'df_test[\"id\"]' 사용\n",
    "#     'prediction': test_preds\n",
    "# })\n",
    "# submission.to_csv('submission.csv', index=False)\n",
    "# print(\"test y value result: submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Marketing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 단계\t설명\n",
    "# test_preds\t고객당 지출 예상 금액\n",
    "# 병합\tdf_test + total_cost_predicted\n",
    "# 타깃팅\t상위 10%, 평균 이상 등\n",
    "# 분석\t고객 특성 분석 (국가, 나이대, 활동 등)\n",
    "# 실행\tVIP 상품 기획, 추천, 광고 타깃팅 등"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. **예측된 Y값(test_preds)은 ‘소비 가능성 추정’**이 됩니다.\n",
    "# 예측값 이름\t의미\n",
    "# test_preds\t이 고객이 얼마나 돈을 쓸 것인지 모델이 추정한 수치\n",
    "# → 마케팅에서는 이걸 기반으로 고지출 고객군(예: 상위 10%)을 타깃팅합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 예측값을 원본 test 데이터와 병합\n",
    "df_test_pred = df_test.copy()\n",
    "df_test_pred['total_cost_predicted'] = test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. 고지출 고객 필터링\n",
    "threshold = df_test_pred['total_cost_predicted'].quantile(0.90)\n",
    "high_spenders = df_test_pred[df_test_pred['total_cost_predicted'] >= threshold]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ✅ 4. 마케팅 전략 설계\n",
    "# 이제 high_spenders를 기반으로 이런 분석을 할 수 있습니다:\n",
    "# 변수\t활용 아이디어\n",
    "# country\t국가별 맞춤 프로모션\n",
    "# travel_with\t가족/커플/혼자 → 맞춤 여행 패키지\n",
    "# main_activity\t관심 기반 관광 테마 구성\n",
    "# night_mainland, night_zanzibar\t체류일수 기반 롱스테이 패키지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ✅ 5. 예시 마케팅 분석 코드\n",
    "# 국가별 평균 예측 소비\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✅ 6. 시각화도 가능\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (.venv)",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
